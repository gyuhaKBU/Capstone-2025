{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91774a1-56b7-4f01-864b-d33360537607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading filtered dataset from: /home/gyuha1118/venvs/capstone/code/datasets/filtered_251127_labeled_NH-001_301A.csv\n",
      "[INFO] Loaded shape: (4777, 21)\n",
      "   ESP32-1_mean  ESP32-1_std  ESP32-1_min  ESP32-1_max  ESP32-1_median  \\\n",
      "0        33.875     8.025629         15.0         38.0            38.0   \n",
      "1        37.625     1.060660         35.0         38.0            38.0   \n",
      "2        38.000     0.000000         38.0         38.0            38.0   \n",
      "3        37.875     0.353553         37.0         38.0            38.0   \n",
      "4        37.625     0.517549         37.0         38.0            38.0   \n",
      "\n",
      "   ESP32-2_mean  ESP32-2_std  ESP32-2_min  ESP32-2_max  ESP32-2_median  ...  \\\n",
      "0        43.500     7.091242         27.0         47.0            47.0  ...   \n",
      "1        46.625     0.744024         45.0         47.0            47.0  ...   \n",
      "2        46.000     2.138090         41.0         47.0            47.0  ...   \n",
      "3        45.750     2.121320         41.0         47.0            47.0  ...   \n",
      "4        45.750     2.121320         41.0         47.0            47.0  ...   \n",
      "\n",
      "   ESP32-3_std  ESP32-3_min  ESP32-3_max  ESP32-3_median  ESP32-4_mean  \\\n",
      "0     9.164177         21.0         47.0            46.5        47.500   \n",
      "1     0.462910         46.0         47.0            47.0        50.875   \n",
      "2     0.000000         47.0         47.0            47.0        51.000   \n",
      "3     0.000000         47.0         47.0            47.0        51.000   \n",
      "4     0.000000         47.0         47.0            47.0        51.000   \n",
      "\n",
      "   ESP32-4_std  ESP32-4_min  ESP32-4_max  ESP32-4_median  label  \n",
      "0     8.000000         28.0         51.0            51.0      0  \n",
      "1     0.353553         50.0         51.0            51.0      0  \n",
      "2     0.000000         51.0         51.0            51.0      0  \n",
      "3     0.000000         51.0         51.0            51.0      0  \n",
      "4     0.000000         51.0         51.0            51.0      0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "[INFO] Features shape: (4777, 20), Labels shape: (4777,)\n",
      "[INFO] Label distribution:\n",
      "label\n",
      "0    1062\n",
      "1    2628\n",
      "2    1087\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[INFO] Split shapes:\n",
      "  X_train: (3821, 20)  y_train: (3821,)\n",
      "  X_val  : (478, 20)  y_val  : (478,)\n",
      "  X_test : (478, 20)  y_test : (478,)\n",
      "\n",
      "[INFO] Scaled shapes:\n",
      "  X_train_2d: (3821, 20)\n",
      "  X_val_2d  : (478, 20)\n",
      "  X_test_2d : (478, 20)\n",
      "\n",
      "[INFO] Number of classes: 3\n",
      "\n",
      "[INFO] Training XGBoost on filtered dataset...\n",
      "[INFO] Training done.\n",
      "\n",
      "=== Train ===\n",
      "Accuracy: 1.0000\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       850\n",
      "           1     1.0000    1.0000    1.0000      2102\n",
      "           2     1.0000    1.0000    1.0000       869\n",
      "\n",
      "    accuracy                         1.0000      3821\n",
      "   macro avg     1.0000    1.0000    1.0000      3821\n",
      "weighted avg     1.0000    1.0000    1.0000      3821\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 850    0    0]\n",
      " [   0 2102    0]\n",
      " [   0    0  869]]\n",
      "\n",
      "=== Val ===\n",
      "Accuracy: 0.9435\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9905    0.9811    0.9858       106\n",
      "           1     0.9407    0.9658    0.9531       263\n",
      "           2     0.9029    0.8532    0.8774       109\n",
      "\n",
      "    accuracy                         0.9435       478\n",
      "   macro avg     0.9447    0.9334    0.9387       478\n",
      "weighted avg     0.9431    0.9435    0.9431       478\n",
      "\n",
      "Confusion matrix:\n",
      "[[104   0   2]\n",
      " [  1 254   8]\n",
      " [  0  16  93]]\n",
      "\n",
      "=== Test ===\n",
      "Accuracy: 0.9477\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9810    0.9717    0.9763       106\n",
      "           1     0.9689    0.9468    0.9577       263\n",
      "           2     0.8707    0.9266    0.8978       109\n",
      "\n",
      "    accuracy                         0.9477       478\n",
      "   macro avg     0.9402    0.9484    0.9439       478\n",
      "weighted avg     0.9492    0.9477    0.9482       478\n",
      "\n",
      "Confusion matrix:\n",
      "[[103   1   2]\n",
      " [  1 249  13]\n",
      " [  1   7 101]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ============================================================\n",
    "# 1. 데이터 경로 설정\n",
    "#    - 필터된 CSV 파일 경로만 맞게 수정하면 된다.\n",
    "# ============================================================\n",
    "BASE_DIR  = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd()\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"datasets\", \"filtered_251127_labeled_NH-001_301A.csv\")\n",
    "# ↑ 파일 이름만 실제 필터 CSV 이름에 맞게 수정\n",
    "\n",
    "print(f\"[INFO] Loading filtered dataset from: {DATA_PATH}\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"[INFO] Loaded shape: {df.shape}\")\n",
    "print(df.head())\n",
    "\n",
    "# ============================================================\n",
    "# 2. 특징 / 라벨 분리\n",
    "#    - label 컬럼 이름이 다르면 여기만 맞춰주면 된다.\n",
    "# ============================================================\n",
    "if \"label\" not in df.columns:\n",
    "    raise ValueError(\"CSV에 'label' 컬럼이 없다. 라벨 컬럼 이름을 확인해라.\")\n",
    "\n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"].astype(int)  # 0/1/2\n",
    "\n",
    "print(f\"[INFO] Features shape: {X.shape}, Labels shape: {y.shape}\")\n",
    "print(\"[INFO] Label distribution:\")\n",
    "print(y.value_counts().sort_index())\n",
    "\n",
    "# ============================================================\n",
    "# 3. Train / Val / Test 분할 (80 / 10 / 10)\n",
    "# ============================================================\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"\\n[INFO] Split shapes:\")\n",
    "print(\"  X_train:\", X_train.shape, \" y_train:\", y_train.shape)\n",
    "print(\"  X_val  :\", X_val.shape,   \" y_val  :\", y_val.shape)\n",
    "print(\"  X_test :\", X_test.shape,  \" y_test :\", y_test.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 4. 스케일링 (StandardScaler)\n",
    "# ============================================================\n",
    "scaler = StandardScaler()\n",
    "X_train_2d = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_val_2d   = scaler.transform(X_val).astype(np.float32)\n",
    "X_test_2d  = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "print(\"\\n[INFO] Scaled shapes:\")\n",
    "print(\"  X_train_2d:\", X_train_2d.shape)\n",
    "print(\"  X_val_2d  :\", X_val_2d.shape)\n",
    "print(\"  X_test_2d :\", X_test_2d.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 5. XGBoost 모델 정의 및 학습\n",
    "#    - 기존 노트북에서 쓰던 하이퍼파라미터와 최대한 비슷하게 맞추면 된다.\n",
    "# ============================================================\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(f\"\\n[INFO] Number of classes: {num_classes}\")\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=num_classes,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "print(\"\\n[INFO] Training XGBoost on filtered dataset...\")\n",
    "xgb_model.fit(\n",
    "    X_train_2d,\n",
    "    y_train,\n",
    "    eval_set=[(X_train_2d, y_train), (X_val_2d, y_val)],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\"[INFO] Training done.\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. 평가 (Train / Val / Test)\n",
    "# ============================================================\n",
    "def eval_split(name, X_split, y_split):\n",
    "    y_pred = xgb_model.predict(X_split)\n",
    "    acc = accuracy_score(y_split, y_pred)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_split, y_pred, digits=4))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_split, y_pred))\n",
    "\n",
    "eval_split(\"Train\", X_train_2d, y_train)\n",
    "eval_split(\"Val\",   X_val_2d,   y_val)\n",
    "eval_split(\"Test\",  X_test_2d,  y_test)\n",
    "\n",
    "# ============================================================\n",
    "# 7. (선택) 모델 / 스케일러 저장\n",
    "# ============================================================\n",
    "# 필요하면 주석 해제해서 저장\n",
    "# from joblib import dump\n",
    "# model_path  = os.path.join(BASE_DIR, \"xgb_filtered_model.joblib\")\n",
    "# scaler_path = os.path.join(BASE_DIR, \"xgb_filtered_scaler.joblib\")\n",
    "# dump(xgb_model, model_path)\n",
    "# dump(scaler, scaler_path)\n",
    "# print(f\"\\n[INFO] Saved model to: {model_path}\")\n",
    "# print(f\"[INFO] Saved scaler to: {scaler_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d1c5e-352d-471d-9dd3-148ccf12e2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (capstone)",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
